** Towards The Positronic Brain: Workshop on Embodied Language Processing and Multimodal Interaction**

## Call for participation and extended abstracts

Organised by Mattias Appelgren and Simon Dobnik

* Date: Friday, 29 November
* Location: [SLTC](https://sltc2024.github.io), Linköping University, Sweden
<!-- * Address: TBD
* Room: TBD 
* Zoom: TBD -->

<!-- Website: https://gu-clasp.github.io/language-and-perception/events/positronic-brain -->

**Important dates:**

* Submission of extended abstracts: 29 Oktober 2024
* Notification of acceptance: 7 November 2024
* Camera Ready: 15 November 2024

All deadlines are 11:59PM CET-00:00 

**Workshop description**

When people hear Artificial Intelligence they often imagine something like Isaac Asimov's Positronic Brain: a brain built out of mathematics, logic, and wires which functions in many respects like a human brain and follows human-like behaviour. It is attached to a body and it can perceive and interact with the world. It has sophisticated language capabilities, speaking about its perception, action and reasoning. However, a common approach to Artificial Intelligence has been to treat language, perception, and action as separate fields with separate goals and problems. Consequently, most systems that we build do not live-up to the beliefs and expectations of every-day users. Integration of several modalities and constructions of agents that can act in sophisticated ways in the world is therefore our next big challenege if we want to approximate human-like robotic agents that Sci-fi authors love. 

This workshop invites researchers and students in the fields of natural language processing, computer science, language technology, computational linguistics, cognitive computing, AI, computer vision, machine learning, robotics, linguistics, cognitive science, and related fields to participate in an open, community-building forum where we discuss current work, challenges, and future directions related to multi-modality, interaction, embodiment, language technology, and AI.  
We encourage contributions in the following and similar topics:
* Grounded language understanding and generation
* Multi-modal or embodied interaction
* Incremental or Online Learning
* Low resource learning and adaptation
* Human-AI Interaction
* Multimodal Dialogue
* Interactive Task Learning

We foresee an interactive workshop with plenty of time for discussion, complemented with invited talks and presentations of on-going or completed research.

<!-- **Invited speakers** -->


**Submissions**

Submissions of up to 2 pages (excluding references) should follow [the ACL formatting template][2], should be in English and contain full contact information of the presenter(s). Authors are also encouraged to submit any other information and materials that they would like to discuss and share with the community about these topics.

Please upload your submissions (zipped in a file name.surname.zip) with your full contact details (names of authors, presenting author, affiliation(s), physical address, email and personal website) at the following [link][https://sigmoid.flov.gu.se/index.php/s/cHEPCyncm99d2S6]

**Registration**

Please register for the workshop using the following link (coming soon)

**Workshop organisers**

\* Mattias Appelgren
\* Simon Dobnik

[1]:	www.gu.se/en/research/language-and-perception-research-group-lp
[2]:	https://2023.aclweb.org/calls/style_and_formatting/
