---
layout: page
title: Workshop on ethics for research and teaching in natural language processing
short_title: Ethics4NLP
permalink: /events/ethics-for-nlp/
---

<img align="right" width="480" src="ethics-for-nlp-480.jpg"/>

Organised by the Stockholm, Uppsala and Umeå interest group in ethics for NLP

* Date: 23rd January 2024
* Location: Humanisten, [Department of Philosophy, Linguistics and Theory of Science (FLoV)](https://www.gu.se/flov/om-oss/kontakt), University of Gothenburg, room J335
* Address: Renströmsgatan 6, floor 3
* Room: J335

### Programme

* __10:00__ Welcome
* __10:15__ Keynote: [Kristina Knaving](https://www.ri.se/en/kristina-knaving) 
* __11:00__ Break
* __11:15__ Keynote: [Stefan Larsson](https://portal.research.lu.se/en/persons/stefan-larsson)
* __12:00__ Lunch
* __13:15__ Keynote: [Juan Carlos Nieves Sanchez](https://www.umu.se/en/staff/juan-carlos-nieves/)
* __14:00__ Lightning talks
  * __14:00__ - 14:10: Iris Guske: Patterns vs particularities: Merging NLP and case study capabilities and responsibilities in life history research
  * __14:10__ - 14:20: Nikolai Ilinykh: Biases in language-and-vision NLP: where we are and what we might need
  * __14:20__ - 14:30: Matilda Arvidsson: Legal discretion and the many meanings of law’s language: Challenges and possibilities for ‘NLP-as-law’s-helping-hand’
  * __14:30__ - 14:40: Thomas Vakili: Privacy in the era of large language models
  * __14:40__ - 14:50: tbc
  * __14:50__ - 15:00: tbc
* __15:00__ Coffee break
* __15:30__ Group discussions
* __16:30__ Summaries of discussions and final thoughts
* __17:30__ Close

### Workshop description

AI tasks related to modelling human language and that focus on decision making (such as identification of patient diagnoses and driving) have developed substantially over the last several years. In many areas it has been claimed that AI learning from data alone has achieved human-like performance, sometimes even better, but due to the nature of these models it is very hard to inspect directly what such models have learned. Instead, we can only observe their performance, which might be biased in one or more ways, and which has societal and environmental implications.

Language technology (also known as computational linguistics or natural language processing) is an interdisciplinary field between linguistics, psychology, cognitive science and computer science that deals with building computational models which can behave as if they understand natural language. Due to the aforementioned developments, a need has been identified by developers, researchers and teachers of language technology that ethical issues related to data collection, training and usage of such models in various real-life applications should also be addressed. We should equip  ourselves as researchers, teachers and students with understanding about the impacts of using such technology or to promote ethically-aware research and utilisation.

Intended participants are researchers, university teachers, masters and PhD students from diverse backgrounds that deal with ethical questions related to development and applications of language technology (language technology and related fields such as computer vision and social robotics, machine learning, philosophy, medicine, law, media, politics, philosophy etc). We foresee an interactive workshop with plenty of time for discussion, complemented with invited talks and presentations of on-going or completed research. Participants are also encouraged to submit extended abstracts (and other materials) that will be shared with others during the workshop and/or presented as posters.

The workshop represents the first forum following the discussions at several Swedish language technology ämnesdagar. Topics that have been addressed there are biases in training data, biases in computational models, personal integrity (anonymisation and pseudonymisation of data), intellectual property rights, using language technology tools to detect non-ethical language use, utilising language technology in under-resourced domains and communities (e.g. minority languages), legal aspects of using language technology, philosophical questions and others. The purpose of the workshop is to further discuss these points from the research perspective and later develop as a short (e.g. 2.5 hec) online course for students of language technology and related fields at the participating sites, as well as general public interested in this area.

### Invited speakers

* [Kristina Knaving](https://www.ri.se/en/person/kristina-knaving), RISE
   * Generative AI, like ChatGPT, DALL-E, and Midjourney, has recently changed our view of what AI can do by entering a traditionally human domain - creativity. What can we truly expect from AI, and what do we want to expect? Kristina will be doing a contemporary and future outlook on AI and generative AI in creative work and society as a whole. There are many opportunities, but also concerns and questions about ethics, democracy, and privacy.
   * *Kristina Knaving* is a senior researcher at RISE, and is responsible for the focus area "The Connected Individual". She has a background in human-computer interaction, visualization, and decision support. Her research focuses on the opportunities, risks, and ethical issues surrounding personal data and AI, and how new technologies affect individuals and society. 
* [Stefan Larsson](https://portal.research.lu.se/en/persons/stefan-larsson), Lund University
   * **The Perils of Being Normative: Towards a Socio-Legal Framework on Social Norms and Adaptive Technologies**
   * While recent progress has been made in several fields of data-intense AI-research, many applications have been shown to be prone to unintendedly reproduce social biases, sexism and stereotyping. As more of design-based, algorithmic or machine learning methodologies, here called adaptive technologies, become embedded in anything from commonly used software to robotics, there is a need for a developed understanding of what role social norms play in the interplay between human expressions and technology, particularly with regards to fairness. In this presentation, Larsson proposes a theoretical framework for the interplay between adaptive technologies and social norms in order to point to the often normative, non-neutral, aspects of developing and implementing adaptive technologies.
   * *Stefan Larsson* is a senior lecturer and Associate Professor in Technology and Social Change at Lund University, Sweden, Department of Technology and Society at LTH. He is a lawyer and socio-legal researcher that holds a PhD in Sociology of Law as well as a PhD in Spatial Planning. He leads a multidisciplinary research group on AI and Society, that studies the impact of AI-supported technologies in various domains, such as on consumer markets, in the public sector, for health, and social robotics.
* [Juan Carlos Nieves](https://www.umu.se/personal/juan-carlos-nieves/), Umeå University
   * **Framework for Trustworthy AI Education**
   * During this presentation, we will present the Framework for Trustworthy AI Education that was developed during the Erasmus Plus project - Trustworthy AI. The main goal of this Framework is to describe the principles and learning strategies to be followed to develop students’ competencies on Trustworthy AI. Some questions that were approached with the Framework for Trustworthy AI Education are: What strategies are needed for effectively introducing the High-Level Expert Group’s requirements in Higher Education? Which competencies and learning outcomes related to Trustworthy AI should Higher Education students develop? How to assess them? etc.
   * *Juan Carlos Nieves* is an associate professor at the Department of Computing Science, Umeå University (UMU) (Sweden).  He is the programme Director of the MSc programme in Artificial Intelligence at UMU. He is the research leader of the Formal Methods for Trustworthy Hybrid Intelligence group, and an affiliated member of the Responsible Artificial Intelligence group at UMU.  He has been serving as an external (Ethical) advisor/reviewer in different EU projects. He has also served as an expert reviewer for different European national research councils. He has been an AI-ethical advisor for European initiatives such as EU BonAPPS and for American initiatives such as fAIr LAC  of the Inter-American Development Bank.


### Lightning talks

* Iris Guske
* Nikolai Ilinykh
* Matilda Arvidsson
   * **Legal discretion and the many meanings of law’s language: Challenges and possibilities for ‘NLP-as-law’s-helping-hand’**
   * In my research I have explored questions on legal discretion and decision making (Arvidsson & Noll 2023), the meaning and matter in law’s language (e.g., Arvidsson 2024, Arvidsson 2023), as well as the “human in the loop” (Arvidsson 2020, 2018) in relation to AI. In my brief talk I will relay some of the findings from my previous research and point to challenges and possibilities for using NLP in legal research and practice.
   * *Matilda Arvidsson* is an associate professor of international law and assistant senior lecturer in jurisprudence at the Department of Law, the University of Gothenburg. Her research interests are interdisciplinary and include AI and law, posthumanism and technology, feminism and ethnography, as well as the embodiment of law in its various forms and in inter-species relations.
 * Thomas Vakili
   * **Privacy in the era of large language models**
   * The NLP community is seeing widespread use of large language models (LLMs) that consist of vast amounts of parameters trained using enormous amounts of data. This combination of parameter count and training data size poses a risk to the privacy of individuals mentioned in the training data of LLMs. In this talk, I will give an overview of these privacy risks and some proposed mitigation strategies. A particular emphasis will be placed on how automatically pseudonymizing training data can reduce privacy risks while preserving their usefulness.


### Submissions

Submissions of up to 4 pages should follow [the ACL formatting template](https://2023.aclweb.org/calls/style_and_formatting/), should be in English and contain full contact information of the presenter(s). Authors are also encouraged to submit any other information that they would like to discuss and share about this topic, in particular if it is relevant for the preparation of the course.

Please upload your submissions (zipped in a file name.surname.zip) with your full contact details [here](https://linux.dobnik.net/cloud/s/dwn7nmY68aEjatK).

### Important dates

* Submission of extended abstracts: 1 December 2023
* Notification of acceptance: 22 December
* Registration: 8 January 2024

All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").

### Registration

Please register for the workshop [here](https://forms.office.com/e/jjbe8FK1jE) by 8 January 2024.

Because of its interactive nature, the workshop will be on-site only. However, future events are planned also for online participation. To be informed about these, please subscribe to our [mailing list](https://listserv.gu.se/sympa/subscribe/ethics-for-nlp). 

You are also encouraged yo join our [Discord](https://discord.gg/fEfkcVu7QG) which we intend to become a meeting point for sharing experiences and materials related to teaching and research in ethics for natural language processing before, during and after the workshop.

### Workshop organisers

  - [Hannah Devinney](https://www.umu.se/en/staff/hannah-devinney/), Umeå University
  - [Simon Dobnik](https://www.gu.se/en/about/find-staff/simondobnik), University of Gothenburg (contact person)
  - [Beáta Megyesi](https://www.su.se/english/profiles/beba5639-1.468162), Stockholm University

### Local organisers  
  
  - [Ricardo Muñoz Sánchez](https://www.gu.se/en/about/find-staff/ricardomunozsanchez), University of Gothenburg
  - [Maria Irena Szawerna](https://www.gu.se/en/about/find-staff/mariaszawerna), University of Gothenburg

### Acknowledgements

We are grateful for the financial support from:

  - the council of vice-chancellors of Gothenburg, Lund, Stockholm, Umeå and Uppsala universities (SLUGU)
  - [Department of Philosophy, Linguistics and Theory of Science (FLoV)](https://www.gu.se/flov/), University of Gothenburg

Image by [Freepik](https://www.freepik.com/free-photo/still-life-illustrating-ethics-concept_26407551.htm)
