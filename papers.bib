
@article{Ettinger:2020ue,
	abstract = {{Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction--- and, in particular, it shows clear insensitivity to the contextual impacts of negation.}},
	author = {Ettinger, Allyson},
	doi = {10.1162/tacl_a_00298},
	eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00298/1923116/tacl\_a\_00298.pdf},
	issn = {2307-387X},
	journal = {Transactions of the Association for Computational Linguistics},
	keywords = {APL-reading-group},
	month = {01},
	pages = {34-48},
	title = {{What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models}},
	url = {https://doi.org/10.1162/tacl\_a\_00298},
	volume = {8},
	year = {2020},
	bdsk-url-1 = {https://arxiv.org/abs/1907.13528}
}

@article{Ahn2022c,
	title = {Do {{As I Can}}, {{Not As I Say}}: {{Grounding Language}} in {{Robotic Affordances}}},
	shorttitle = {Do {{As I Can}}, {{Not As I Say}}},
	author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Ho, Daniel and Hsu, Jasmine and Ibarz, Julian and Ichter, Brian and Irpan, Alex and Jang, Eric and Ruano, Rosario Jauregui and Jeffrey, Kyle and Jesmonth, Sally and Joshi, Nikhil J. and Julian, Ryan and Kalashnikov, Dmitry and Kuang, Yuheng and Lee, Kuang-Huei and Levine, Sergey and Lu, Yao and Luu, Linda and Parada, Carolina and Pastor, Peter and Quiambao, Jornell and Rao, Kanishka and Rettinghouse, Jarek and Reyes, Diego and Sermanet, Pierre and Sievers, Nicolas and Tan, Clayton and Toshev, Alexander and Vanhoucke, Vincent and Xia, Fei and Xiao, Ted and Xu, Peng and Xu, Sichun and Yan, Mengyuan},
	year = {2022},
	month = apr,
	journal = {arXiv:2204.01691 [cs]},
	eprint = {2204.01691},
	eprinttype = {arxiv},
	primaryclass = {cs},
	abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's ``hands and eyes,'' while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at say-can.github.io.},
	archiveprefix = {arXiv},
	langid = {english},
	keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Robotics}
}
