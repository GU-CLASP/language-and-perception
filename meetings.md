---
layout: page
title: Reading group
permalink: /meetings/
---

  - The reading group meets on even Fridays 10-12 in the seminar room on the 5th floor of Humanistiska fakulteten, Renströmsgatan 6.

  - Sometimes, and more recently, we meet [online on Zoom](https://gu-se.zoom.us/j/726750116), requires GU-login.

  - Participating gives you [course credit](https://gu-clasp.github.io/language-and-perception/courses/).

  - To add a paper suggestion, simply edit me [here](https://github.com/GU-CLASP/language-and-perception/blob/master/meetings.md). Consider also adding a bibtex entry [here](https://github.com/GU-CLASP/language-and-perception/blob/master/papers.bib). 
  
  - If available, prefer links to the published (e.g. ACL) rather than arXiV versions. Papers that are not published online can be uploaded [here](https://linux.dobnik.net/cloud/index.php/s/Z2iPGa28Mexyz24).
  
  - Subscribe to [our mailing list](https://listserv.gu.se/sympa/subscribe/cogsys) to follow discussions.


### Next

  * P. Lison, J. Barnes, and A. Hubin. [skweak: Weak supervision made easy for NLP.](https://aclanthology.org/2021.acl-demo.40) In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, pages 337–346, Online, Aug. 2021. Association for Computational Linguistics.



### Suggestions

Please add here (bibtex [here](https://github.com/GU-CLASP/language-and-perception/blob/master/papers.bib)) any papers you would like to suggest for the reading group. Papers that have been here for a while might be moved to [the attic](papers-attic.md). 

  * Author. Year. Paper.
  *  J. H. Lee, M. Kerzel, K. Ahrens, C. Weber, and S. Wermter. [What is right for me is not yet right for you: A dataset for grounding relative directions via multi-task learning.](https://arxiv.org/abs/2205.02671) arXiv, arXiv:2205.02671 [cs.CV], 2022. [Dataset](https://github.com/knowledgetechnologyuhh/grid-3d)
  *  Y. Liu and G. Emerson. [Learning functional distributional semantics with visual data.](https://aclanthology.org/2022.acl-long.275) In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3976–3988, Dublin, Ireland, May 2022. Association for Computational Linguistics.
  *  F. Liu, G. Emerson, and N. Collier. [Visual spatial reasoning.](https://arxiv.org/abs/2205.00363) arXiv, arXiv:2205.00363 [cs.CL], 2022.
  *  E. Bugliarello, R. Cotterell, N. Okazaki, and D. Elliott. [Multimodal pretraining unmasked: A meta- analysis and a unified framework of vision-and-language BERTs.](https://aclanthology.org/2021.tacl-1.58) Transactions of the Association for Computational Linguistics, 9:978–994, 2021.
  *  L. W. Barsalou. [Grounded cognition.](https://doi.org/10.1146/annurev.psych.59.103006.093639) Annual Review of Psychology, 59:617–645, 2008.
  *  R. Bernardi and S. Pezzelle. [Linguistic issues behind visual question answering.](https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12417) Language and Linguistics Compass, 15(6):elnc3.12417, 2021.
  *  S. Buch, L. Fei-Fei, and N. D. Goodman. [Neural Event Semantics for Grounded Language Understanding.](https://doi.org/10.1162/tacl\_a\_00402) Transactions of the Association for Computational Linguistics, 9:875–890, 08 2021.
  *  J. Cho, J. Lei, H. Tan, and M. Bansal. [Unifying vision-and-language tasks via text generation.](https://arxiv.org/abs/2102.02779) arXiv, arXiv:2102.02779 [cs.CL], 2021.
  *  G. Collell and M.-F. Moens. [Learning representations specialized in spatial knowledge: Leveraging language and vision.](https://www.transacl.org/ojs/index.php/tacl/article/view/1214) Transactions of the Association for Computational Linguistics, 6:133–144, 2018.
  *  I. Dasgupta, C. Kaeser-Chen, K. Marino, A. Ahuja, S. Babayan, F. Hill, and R. Fergus. [Collaborating with language models for embodied reasoning.](https://arxiv.org/abs/2302.00763) arXiv, arXiv:2302.00763 [cs.LG], 2023.
  *  R. Dess`ı, E. Gualdoni, F. Franzon, G. Boleda, and M. Baroni. [Communication breakdown: On the low mutual intelligibility between human and neural captioning.](https://arxiv.org/abs/2210.11512) arXiv, arXiv:2210.11512 [cs.CL], 2022.
  *  T. Dong, A. Testoni, L. Benotti, and R. Bernardi. [Visually grounded follow-up questions: a dataset of spatial questions which require dialogue history.](https://aclanthology.org/2021.splurobonlp-1.3) In Proceedings of Second International Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics, pages 22–31, Online, Aug. 2021. Association for Computational Linguistics.
  *  C. Greco, B. Plank, R. Fern ́andez, and R. Bernardi. [Psycholinguistics meets continual learning: Measuring catastrophic forgetting in visual question answering.](https://www.aclweb.org/anthology/P19-1350) In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3601–3605, Florence, Italy, July 2019. Association for Computational Linguistics.
  *  J. Lu, D. Batra, D. Parikh, and S. Lee. [Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks.](http://arxiv.org/abs/1908.02265) arXiv, arXiv:1908.02265 [cs.CV], 2019.
  *  J. Lu, V. Goswami, M. Rohrbach, D. Parikh, and S. Lee. [12-in-1: Multi-task vision and language representation learning.](https://openaccess.thecvf.com/content_CVPR_2020/html/Lu_12-in-1_Multi-Task_Vision_and_Language_Representation_Learning_CVPR_2020_paper.html) In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1–10, June 2020.
  *  I. Parfenova, D. Elliott, R. Fern ́andez, and S. Pezzelle. [Probing cross-modal representations in multi- step relational reasoning.](https://aclanthology.org/2021.repl4nlp-1.16) In Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021), pages 152–162, Online, Aug. 2021. Association for Computational Linguistics.
  *  A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. [Learning transferable visual models from natural language supervision.](https://proceedings.mlr.press/v139/radford21a.html) In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 8748–8763. PMLR, 18–24 Jul 2021.
  *  T. Ramalho, T. Kocisky ́, F. Besse, S. M. A. Eslami, G. Melis, F. Viola, P. Blunsom, and K. M. Hermann. [Encoding spatial relations from natural language.](http://arxiv.org/abs/1807.01670) arXiv, arXiv:1807.01670 [cs.CL]:16, July 5 2018.
  *  F. Sadeghi, S. K. Kumar Divvala, and A. Farhadi. [Viske: Visual knowledge extraction and question answering by visual verification of relation phrases.](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Sadeghi_VisKE_Visual_Knowledge_2015_CVPR_paper.html) In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1456–1464, 2015.
  *  S. Shen, L. H. Li, H. Tan, M. Bansal, A. Rohrbach, K. Chang, Z. Yao, and K. Keutzer. [How much can CLIP benefit vision-and-language tasks?](https://arxiv.org/abs/2107.06383) arXiv, arXiv:2107.06383 [cs.CV], 2021.
  *  C. Silberer, S. Zarrieß, M. Westera, and G. Boleda. [Humans meet models on object naming: A new dataset and analysis.](https://aclanthology.org/2020.coling-main.172) In Proceedings of the 28th International Conference on Computational Linguistics, pages 1893–1905, Barcelona, Spain (Online), Dec. 2020. International Committee on Computational Linguistics.
  *  A. Singh, R. Hu, V. Goswami, G. Couairon, W. Galuba, M. Rohrbach, and D. Kiela. [Flava: A founda- tional language and vision alignment model.](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html) In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 15638–15650, June 2022.
  *  G. Skantze and B. Willemsen. [CoLLIE: Continual learning of language grounding from language-image embeddings.](https://doi.org/10.1613%2Fjair.1.13689) Journal of Artificial Intelligence Research, 74:1201–1223, jul 2022.
  *  E. Sood, F. K ̈ogel, F. Strohm, P. Dhar, and A. Bulling. [VQA-MHUG: A gaze dataset to study multimodal neural attention in visual question answering.](https://aclanthology.org/2021.conll-1.3) In Proceedings of the 25th Conference on Computational Natural Language Learning, pages 27–43, Online, Nov. 2021. Association for Computational Linguistics.
  *  W. Su, X. Zhu, Y. Cao, B. Li, L. Lu, F. Wei, and J. Dai. [VL-BERT: Pre-training of generic visual- linguistic representations.](https://arxiv.org/abs/1908.08530) arXiv, arXiv:1908.08530 [cs.CV], 2019.
  *  H. Tan and M. Bansal. [LXMERT: Learning cross-modality encoder representations from transformers.](https://www.aclweb.org/anthology/D19-1514) In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5100–5111, Hong Kong, China, Nov. 2019. Association for Computational Linguistics.
  *  M. Tsimpoukelli, J. L. Menick, S. Cabi, S. M. A. Eslami, O. Vinyals, and F. Hill. [Multimodal few- shot learning with frozen language models.](https://proceedings.neurips.cc/paper/2021/file/01b7575c38dac42f3cfb7d500438b875-Paper.pdf) In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 200–212. Curran Associates, Inc., 2021.
  *  P. Villalobos, J. Sevilla, L. Heim, T. Besiroglu, M. Hobbhahn, and A. Ho. [Will we run out of data? an analysis of the limits of scaling datasets in machine learning.](https://doi.org/10.48550/arXiv.2211.04325) arXiv, arXiv:2211.04325 [cs.LG], 2022.
  *  V. Wang-Mascianica and B. Coecke. [Talking space: inference from spatial linguistic meanings.](https://doi.org/10.48550/arXiv.2109.06554) arXiv, arXiv:2109.06554 [cs.CL]:1–33, September 16 2021.
  *  M. Zare, A. Ayub, A. Liu, S. Sudhakara, A. Wagner, and R. Passonneau. [Dialogue policies for learning board games through multimodal communication.](https://aclanthology.org/2020.sigdial-1.41) In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 339–351, 1st virtual meeting, July 2020. Association for Computational Linguistics.
  *  Z. Zhang, Y. Wang, Q. Wu, and F. Chen. [Visual relationship attention for image captioning.](https://ieeexplore.ieee.org/abstract/document/8851832) In 2019 International Joint Conference on Neural Networks (IJCNN), pages 1–8, July 2019.
  *  C. Zheng, Q. Guo, and P. Kordjamshidi.  [Cross-modality relevance for reasoning on language and vision.](https://aclanthology.org/2020.acl-main.683) In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7642– 7651, Online, July 2020. Association for Computational Linguistics.


### Read

  * J. Andreas and D. Klein. [Analogs of linguistic structure in deep representations.](https://aclanthology.org/D17-1311) In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2893–2897, Copenhagen, Denmark, Sept. 2017. Association for Computational Linguistics. Participants: Adam, Nikolai, Alex, Vidya and Simon

  * A. Ji, N. Kojima, N. Rush, A. Suhr, W. K. Vong, R. Hawkins, and Y. Artzi. [Abstract visual reasoning with tangram shapes.](https://aclanthology.org/2022.emnlp-main.38) In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 582–601, Abu Dhabi, United Arab Emirates, Dec. 2022. Association for Computational Linguistics. [video](https://youtu.be/hCmX8ZFIVf8) [arXiV](https://arxiv.org/abs/2211.16492) Participants: Nikolai, Adam, Elham, Katya, Elen and Simon

  * J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. Chi, Q. Le, and D. Zhou. [Chain of thought prompting elicits reasoning in large language models.]( https://arxiv.org/pdf/2201.11903.pdf) arXiv, arXiv:2201.11903 [cs.CL]:1–43, 2022. Participants: Alex, Staffan, Vidya and Simon

  * J. Andreas. [Language models as agent models.](https://arxiv.org/abs/2212.01681) arXiv, arXiv:2212.01681 [cs.CL], December 3 2022. Suggested by Nikolai. Participants: Aram, Staffan, Robin, Adam, Vidya, Bill, Alex, Simon and Nikolai

  * [(Re)construing meaning in NLP.](https://aclanthology.org/2020.acl-main.462) S. Trott, T. T. Torrent, N. Chang, and N. Schneider. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5170–5184, Online, July 2020. Association for Computational Linguistics. Participants: Alex, Robin, Vidya, Adam, Katya, Tiago, Simon, Nikolai, Staffan, Dominik. 2022-12-16.

  * [Entropy minimization in emergent languages.](https://dl.acm.org/doi/pdf/10.5555/3524938.3525422) E. Kharitonov, R. Chaabouni, D. Bouchacourt, and M. Baroni. In H. D. III and A. Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5220–5230. PMLR, 13–18 Jul 2020. Participants: Adam, Nikolai, Alex, Aram, Robin, Elham, Simon. 2022-11-18.

  * [Norm Participation Grounds Language.](https://arxiv.org/pdf/2206.02885.pdf) David Schlangen, 2022. arXiv pre-print. (suggested by ..., RoM, participants: Staffan, Alex, Elham, Vidya, Amandine, Bill, Chris, Robin, Aram, Simon, Nikolai).

  * [Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines. (2022).](https://arxiv.org/pdf/2205.11558.pdf) Kumar, Sreejan, Carlos G., Correa, Ishita, Dasgupta, Raja, Marjieh, Michael Y., Hu, Robert D., Hawkins, Nathaniel D., Daw, Jonathan D., Cohen, Karthik, Narasimhan, and Thomas L., Griffiths. (suggested by Robin, RoM/LaP, participants: Vidya, Aram, Amandine, Robin, Nikolai, Simon, Elham, 2022-06-03).

  * Lalchand Pandia, Yan Cong, and Allyson Ettinger. [Pragmatic competence of pre-trained language models through the lens of discourse connectives.](https://aclanthology.org/2021.conll-1.29.pdf). CoNLL 2021. (suggested by Nikolai, RoM, participants: Nikolai, Simon, Bill, Aram, Robin, 2022-05-06).

  * Wang, P., Li, X., & Hammer, P. (2018). [Self in NARS, an AGI System.](https://www.frontiersin.org/articles/10.3389/frobt.2018.00020/full) Frontiers in Robotics and AI, 5 (suggested by Vlad, RoM/LaP, participants: Vidya, Aram, Adam, Eleni, Alex, Vlad, Staffan, Ellen, Robin, Nikolai, Bill, 2022-04-22).

  * [Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments.](https://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.pdf) Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, Anton van den Hengel; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 3674-3683 (suggested by Nikolai, LaP, 2022-04-08)

  * Guy Emerson. 2020. [What are the Goals of Distributional Semantics?.](https://aclanthology.org/2020.acl-main.663.pdf) In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7436–7453, Online. Association for Computational Linguistics. (suggested by Adam, RoM, 2022-03-25)

  * Tzuf Paz-Argaman, Reut Tsarfaty, Gal Chechik, and Yuval Atzmon. 2020. [ZEST: Zero-shot Learning from Text Descriptions using Textual Similarity and Visual Summarization.](https://aclanthology.org/2020.findings-emnlp.50.pdf) In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 569–579, Online. Association for Computational Linguistics. (suggested by Bill and Nikolai, LaP, 2022-03-11)

  * A. Ettinger. [What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models.](https://doi.org/10.1162/tacl\_a\_00298) Transactions of the Association for Computational Linguistics, 8:34–48, 01 2020. (suggested by Adam, RoM, 2022-02-25)

  * Ben-Yosef Guy and Ullman Shimon. 2018. [Image interpretation above and below the object level. Interface Focus](http://doi.org/10.1098/rsfs.2018.0020). 8:20180020. 20180020. (suggested by Nikolai/Simon, LaP, 2022-02-11)

  * Takmaz, E., Giulianelli, M., Pezzelle, S., Sinclair, A., & Fernández, R. (2020). [Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts.](https://aclanthology.org/2020.emnlp-main.353.pdf) In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4350–4368). Association for Computational Linguistics. AND [Zero-Shot Visual Grounding of Referring Utterances in Dialogue.](https://openreview.net/forum?id=JcxhaCjSlGz) Anonymous submission to ACL ARR 2021 November round. (suggested by Simon/Nikolai), LaP, 2022-01-28

  * Lampert, C., Nickisch, H., & Harmeling, S. (2014). [Attribute-Based Classification for Zero-Shot Visual Object Categorization.](https://aclanthology.org/2020.emnlp-main.353.pdf) IEEE Trans. Pattern Anal. Mach. Intell., 36(3), 453–465. (suggested by Bill) LaP, 2021-12-17

  * Cangelosi, A., & Harnad, S. (2001). [The adaptive advantage of symbolic theft over sensorimotor toil: Grounding language in perceptual categories.](https://pearl.plymouth.ac.uk/bitstream/handle/10026.1/3619/Cangelosi-Harnad-EoC-2002.pdf?sequence=1&isAllowed=y) Evolution of communication, 4(1), 117-142. (suggested by Alex) LaP/RoM, 2021-12-03

  * Spliethöver, M., & Wachsmuth, H. (2020). [Argument from Old Man's View: Assessing Social Bias in Argumentation.](https://aclanthology.org/2020.argmining-1.9.pdf) In Proceedings of the 7th Workshop on Argument Mining (pp. 76–87). Association for Computational Linguistics. (suggested by Anna/Simon) RoM 2021-11-05

  * Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza Merzic, & Stephen Clark (2021). [Grounded Language Learning Fast and Slow.](https://openreview.net/forum?id=wpSWuz_hyqA) In International Conference on Learning Representations. (suggested by Nikolai) LaP/RoM 2021-10-22

  * The Singleton Fallacy: Why Current Critiques of Language Models Miss the Point Magnus Sahlgren (AI Sweden, Stockholm, Sweden) and Fredrik Carlsson 
(RISE, Stockholm, Sweden) https://doi.org/10.3389/frai.2021.682578 (suggested by Robin) RoM 2021-10-08

  * Is it possible for language models to achieve language understanding? Christofer Potts (2020) [blog post](https://chrisgpotts.medium.com/is-it-possible-for-language-models-to-achieve-language-understanding-81df45082ee2) (Recommended by Robin, would like to read: Robin) RoM 2021-10-08

  * Trapit Bansal, David Belanger, Andrew McCallum (2016): Ask the GRU: Multi-task Learning for Deep Text Recommendations
(https://arxiv.org/abs/1609.02116) (recommended by Aram, would like to read: Nikolai) RoM 2021-07-02

  * Semantic Representation for Dialogue Modeling. Xuefeng Bai, Yulong Chen, Linfeng Song, Yue Zhang. [paper](https://arxiv.org/pdf/2105.10188.pdf) (from Adam) 2021-06-18

  * Yuchen Liang, Chaitanya Ryali, Benjamin Hoover, Saket Navlakha, Leopold Grinberg, Mohammed J Zaki, Dmitry Krotov [Can a Fruit Fly Learn Word Embeddings?](https://arxiv.org/pdf/2101.06887.pdf) (Recommended by Adam, would like to read: Robin, Anna, Adam) 2021-06-04  

  * Vulić, Ivan, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, and Anna Korhonen. (2020) "Probing pretrained language models for lexical semantics." https://www.aclweb.org/anthology/2020.emnlp-main.586.pdf (Recommended by Felix, would like to read: Simon, Nikolai) 2021-05-21  

  * William Merrill, Yoav Goldberg, Roy Schwartz, & Noah A. Smith. (2021). Provable Limitations of Acquiring Meaning from Ungrounded Form: What will Future Language Models Understand? [paper](https://arxiv.org/pdf/2104.10809.pdf) TACL (Recommended by Nikolai, would like to read: Nikolai) 2021-05-07  

  * Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?🦜. (http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf) (Recommended by Anna, would like to read: Anna, Felix) 2021-04-23 

  * Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, & Dhruv Batra (2018). Embodied Question Answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). [paper](https://embodiedqa.org/paper.pdf) 2021-04-09  

  * Herbelot, A., & Vecchi, E. M. (2015). Building a shared world: Mapping distributional to model-theoretic semantic spaces. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (pp. 22-32).(https://www.cl.cam.ac.uk/~ah433/emnlp2015.pdf) (recommended by Staffan, would like to read: Robin, Simon)

  * Nguyen, Phi & Joty, Shafiq & Hoi, Steven & Socher, Richard. (2020). Tree-structured Attention with Hierarchical Accumulation. [paper](https://openreview.net/forum?id=HJxK5pEYvr) (recommended by Axel, would like to read: Robin, Axel, Simon, Adam)

  * Gao, J., Peng, B., Li, C., Li, J., Shayandeh, S., Liden, L., & Shum, H. Y. (2020). Robust conversational ai with grounded text generation. arXiv preprint arXiv:2009.03457. https://arxiv.org/abs/2009.03457 (Recommended by Staffan, would like to read: Robin, Nikolai, Simon, Anna)

  * Vig, J., & Belinkov, Y. (2019). [Analyzing the Structure of Attention in a Transformer Language Model.](https://www.aclweb.org/anthology/W19-4808.pdf). In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 63-76, Florence, Italy, August 2019. (recommended by Nikolai, would like to read: Axel, Felix, Anna, Simon) 2021-02-12

 * Katrin Erk and Aurélie Herbelot (2020) How to Marry a Star: probabilistic constraints for meaning in context, https://arxiv.org/pdf/2009.07936.pdf, [revised version](https://drive.google.com/file/d/1BW9VCFAPZdUcO0qRIUNVSDAx3SQwDuy3/view?usp=sharing) from Katrin (recommended by Robin)

 * ++++++++ J. D. Hwang, C. Bhagavatula, R. L. Bras, J. Da, K. Sakaguchi, A. Bosselut, and Y. Choi. [Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs.](https://arxiv.org/abs/2010.05953) arXiv, arXiv:2010.05953 [cs.CL]:1–17, 2020. [Video of a talk.](https://youtu.be/h2wzQKRAdA8) (Recommended by Nikolai, credit for either APL or ROM, would like to read: Nikolai, Anna, Felix, Axel, Robin, Staffan, Ellen, Simon) 2021-01-29

 * Conneau, A., Lample, G., Ranzato, M. A., Denoyer, L., & Jégou, H. (2017). [Word translation without parallel data.](https://arxiv.org/pdf/1710.04087.pdf)  (Recommended by Adam, credit for ROM) 2020-12-11
 
 * T. Scialom, P. Bordes, P.-A. Dray, J. Staiano, and P. Gallinari. [What BERT sees: Cross-modal transfer for visual question generation.](https://arxiv.org/abs/2002.10832) arXiv, arXiv:2002.10832 [cs.CL]:1–11, November 2 2020. (recommended by Nikolai), 2020-12-04

 * M. Artetxe, G. Labaka, and E. Agirre. [A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings.](https://www.aclweb.org/anthology/P18-1073) In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 789–798, Melbourne, Australia, July 2018. Association for Computational Linguistics. (comes with a video and slides) (Adam)
    
 * M. Artetxe, G. Labaka, and E. Agirre. [Learning bilingual word embeddings with (almost) no bilingual data.](https://www.aclweb.org/anthology/P17-1042/) In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 451–462, Vancouver, Canada, July 2017. Association for Computational Linguistics. (comes with a video and slides) (recommended by Axel and Adam) 2020-10-16

 * J. Y. Chai, Q. Gao, L. She, S. Yang, S. Saba-Sadiya, and G. Xu. [Language to action: Towards interactive task learning with physical agents.](https://doi.org/10.24963/ijcai.2018/1) In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, pages 2–9. International Joint Conferences on Artificial Intelligence Organization, 7 2018. 2020-10-02 [Talk](https://slideslive.com/38929802/situated-humanmachine-communication), [workshop with the talk](https://nli-acl2020.github.io/)

 * J. Pustejovsky and N. Krishnaswamy. [Situated meaning in multimodal dialogue: Human-robot and human-computer interactions.](http://www.voxicon.net/wp-content/uploads/2020/07/TAL_2020-13.pdf) Journal article manuscript, Department of Computer Science, Brandeis University, July 2020. (recommneded by Bill and Nikolai) 2020-09-21 [Talk](https://www.youtube.com/watch?v=IwIvn64mT3U)

 * A. Knott and M. Takac. [Roles for event representations in sensorimotor experience, memory formation, and language processing.](https://doi.org/10.1111/tops.12497) Topics in Cognitive Science, 2020. ([local copy](https://slack-files.com/files-pri-safe/TU15D2JSX-F019M7Z47RA/knott-takac-tops20.pdf?c=1598966339-11af60792c469780)) (recommended by Robin) 2020-09-04

 * Parizi, A. H., & Cook, P. (2020). [Evaluating Sub-word embeddings in cross-lingual models.](https://www.aclweb.org/anthology/2020.lrec-1.330.pdf) Proceedings ofthe 12th Conference on Language Resources and Evaluation (LREC 2020), May, 2712–2719. (recommended by Tewodros) 2020-06-26

 * Pezzelle, S., & Fernández, R. (2019). Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual Contexts. arXiv preprint arXiv:1908.10285. [paper](https://arxiv.org/pdf/1908.10285.pdf) (recommended by Staffan) 2020-06-12

 * Talk: Míriam Sánchez-Alcón: The significance of applying attention to Visual Question Answering  [paper](https://gubox.app.box.com/s/djn8w0k2qlmkgbdsr8yk0dsz22r1fjsj) and  Wu, J., & Mooney, R. J. (2018). Faithful Multimodal Explanation for Visual Question Answering [cs.CL], 2020. [paper](http://arxiv.org/abs/1809.02805) (recommended by Simon) 2020-05-29

 * Goodman, N. D., & Frank, M. C. (2016). Pragmatic Language Interpretation as Probabilistic Inference. In Trends in Cognitive Sciences. [paper](http://langcog.stanford.edu/papers_new/goodman-2016-underrev.pdf) (recommended by Bill) 2020-05-15

 * Talk: David Alfter: Visual features in textual complexity classification: a case study on pictograms  [paper](https://gubox.box.com/shared/static/nuyn4p02bcj8pok1lmd9huf54wfmt8an.pdf) and  Y. Bisk, A. Holtzman, J. Thomason, J. Andreas, Y. Bengio, J. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich, N. Pinto, and J. Turian. Experience grounds language. arXiv, arXiv:2004.10151 [cs.CL], 2020. [paper](https://arxiv.org/abs/2004.10151) 2020-04-30

* J. Krause, J. Johnson, R. Krishna, and L. Fei-Fei. A hierarchical approach for generating descriptive image paragraphs. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3337–3345, July 21–26 2017. [paper](https://arxiv.org/pdf/1611.06607.pdf) (recommended by Nikolai)

 * Tai, Kai & Socher, Richard & Manning, Christoper. (2015). Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks. 1. 10.3115/v1/P15-1150. [paper](https://arxiv.org/abs/1503.00075) (recommended by Axel) 2020-04-03

  * Cohn-Gordon, R., Goodman, N., & Potts, C. (2018). Pragmatically Informative Image Captioning with Character-Level Inference. [paper](http://arxiv.org/abs/1804.05417) (recommended by Nikolai) 2020-03-20

  * Anonymous (2020), Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data.
[paper](https://openreview.net/forum?id=GKTvAcb12b) (recommended by Mehdi) 2020-03-06 

  * X. Yu, H. Zhang, Y. Song, Y. Song, and C. Zhang. What you see is what you get: Visual pronoun coreference resolution in dialogues. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5122–5131, Hong Kong, China, Nov. 2019. Association for Computational Linguistics. [paper](https://www.aclweb.org/anthology/D19-1516) (recommended by Sharid and Simon) 2019-12-13 
  
  * Research talk by [Vaishnavi Annavarjula](http://insidr.nu/eton-ab/) 2019-12-02

  * F. Cavicchio, D. Melcher, and M. Poesio. The effect of linguistic and visual salience in visual world studies. Frontiers in Psychology, 5:176, 2014. [paper](https://www.frontiersin.org/article/10.3389/fpsyg.2014.00176) (recommended by Sharid and Simon) 2019-11-15

 * S. Kottur, J. M. Moura, D. Parikh, D. Batra, and M. Rohrbach. Visual coreference resolution in visual dialog using neural module networks. In Proceedings of the European Conference on Computer Vision (ECCV), pages 153–169, 2018. (recommended by Sharid and Simon) [link](http://openaccess.thecvf.com/content_ECCV_2018/papers/Satwik_Kottur_Visual_Coreference_Resolution_ECCV_2018_paper.pdf) 2019-10-04

  * J. M. Cano Sant ́ın. Fast visual grounding in interaction: bringing few-shot learning with neural networks to an interactive robot. Masters in language technology (mlt), 30 hec, Department of Philosophy, Lin- guistics and Theory of Science (FLOV), University of Gothenburg, Gothenburg, Sweden, September 18 2019. Supervisor: Simon Dobnik and Mehdi Ghanimifard, examiner: Aarne Ranta. 2019-09-18

  * Peters, Matthew E., et al. "Dissecting contextual word embeddings: Architecture and representation." Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509 Brussels, Belgium, October 31 - November 4, 2018. [link](https://aclweb.org/anthology/D18-1179) (recommended by Felix) 2019-05-03

  * Pragst, Louisa, et al. “On the Vector Representation of Utterances in Dialogue Context.” Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018), European Language Resource Association, 2018. [link](http://aclweb.org/anthology/L18-1124) (recommended by Bill Nobel) 2019-04-05

  * Forestier S, Oudeyer P-Y.  (2017)  A Unified Model of Speech and Tool Use Early Development. Proceedings of the 39th Annual Meeting of the Cognitive Science Society. [link](http://sforestier.com/node/32) (recommended by Sylvie Saget) 2019-03-08

  * Li, J., Chen, X., Hovy, E., & Jurafsky, D. (2016). Visualizing and Understanding Neural Models in NLP. In Proceedings of NAACL-HLT (pp. 681-691). [link](http://www.aclweb.org/anthology/N16-1082) (recommended by Felix Morger) 2019-02-22

  * G. Collell, L. V. Gool, and M. Moens. Acquiring common sense spatial knowledge through implicit spatial templates. arXiv, arXiv:1711.06821 [cs.AI]:1–8, 2017. [link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16232/16259) 2019-02-08

  * N. Schneider, J. D. Hwang, V. Srikumar, J. Prange, A. Blodgett, S. R. Moeller, A. Stern, A. Bitan, and O. Abend. Comprehensive supersense disambiguation of English prepositions and possessives. arXiv, arXiv:1805.04905 [cs.CL], 2018. (recommended by Bill) 2018-12-06

  * B. Landau and R. Jackendoff. “what” and “where” in spatial language and spatial cognition. Behavioral and Brain Sciences, 16(2):217–238, 255–265, 1993. Background: B. Landau. Update on “what” and “where” in spatial language: A new division of labor for spatial terms. Cognitive Science, 41(2):321–350, 2016. (recommended by Mehdi) 2018-11-22

  * A. Conneau, G. Kruszewski, G. Lample, L. Barrault, and M. Baroni. What you can cram into a single vector: Probing sentence embeddings for linguistic properties. arXiv, arXiv:1805.01070 [cs.CL], 2018. (recommended by Bill) [link](https://arxiv.org/pdf/1805.01070.pdf) 2018-11-02 

  * W. Monroe, R. X. D. Hawkins, N. D. Goodman, and C. Potts. Colors in context: A pragmatic neural model for grounded language understanding. Transactions of the Association for Computational Linguistics, 5:325–338, 2017. 2018-10-15  (recommended by Simon and Mehdi) [link](http://www.aclweb.org/anthology/Q17-1023)

  * I. Vulić and N. Mrkšić. Specialising word vectors for lexical entailment. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1134–1145. Association for Computational Linguistics, 2018 (recommended by Bill) 2018-10-08 [link](http://aclweb.org/anthology/N18-1103)

  * ACL 2018 report by Mehdi Ghanimifard 2018-09-21: [link](https://docs.google.com/presentation/d/13zAcf5jFV516Q-fL9gwS_0NahTc5_EWxLkap3sShc4E/edit?usp=sharing)

  * Matteo Mossio and Dario Taraborelli. Action-dependent perceptual invariants: From ecological to sensorimotor approaches. Consciousness and cognition, 17(4):1324-1340, 2008. (recommended by Sylvie) 2018-06-01

  * S. C. Marsella and J. Gratch. Ema: A process model of appraisal dynamics. Cognitive Systems Research, 10(1):70–90, 2009. (recommended by Vlad) 2018-05-04

  * Viethen, Jette, Robert Dale, and Markus Guhe. "Generating subsequent reference in shared visual scenes: Computation vs. re-use." Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011. [link](https://aclanthology.info/pdf/D/D11/D11-1107.pdf) (recommended by Sylvie) 2018-03-23

  * Stefanie Tellex: Learning Models of Language, Action and Perception for Human-Robot Collaboration  [video](https://www.youtube.com/watch?v=Yqn0kdS8dHE&t=3035s) 2018-03-16

  * J. Y. Chai, R. Fang, C. Liu, and L. She. Collaborative language grounding toward situated human-robot dialogue. AI Magazine, 37(4), 2016. (recommended by Mehdi and Simon) 2018-02-09

  * J. Pustejovsky. From affordances to events: Communicating action through language and gesture. Paper manuscript, Department of Computer Science, Brandeis University, Waltham, MA USA, January 2018. (recommended by Robin)

  * Fodor, J. (1998). There are no recognitional concepts; not even RED. Philosophical issues, 9, 1-14. (recommended by Staffan)  (2018-01-12)

  * J. Johnson, B. Hariharan, L. van der Maaten, J. Hoffman, F. Li, C. L. Zitnick, and R. B. Girshick. Inferring and executing programs for visual reasoning. CoRR, abs/1705.03633(n):n, 2017. [link](https://arxiv.org/abs/1705.03633) (recommended by Mehdi) 2017-12-08

  * A. Lücking. Modeling co-verbal gesture perception in type theory with records. In Computer Science and Information Systems (FedCSIS), 2016 Federated Conference on, pages 383–392. IEEE, 2016. (recommended by Vlad)

  * M. Malinowski, M. Rohrbach, and M. Fritz. Ask your neurons: A neural-based approach to answering questions about images. In Proceedings of the IEEE International Conference on Computer Vision, pages 1–9, 2015. [link](https://www.d2.mpi-inf.mpg.de/sites/default/files/iccv15-neural_qa.pdf) (recommended by Simon) 2017-10-27

  * H. M. Hersh and A. Caramazza. A fuzzy set approach to modifiers and vagueness in natural language. Journal of Experimental Psychology: General, 105(3):254, 1976. [link](http://www.wjh.harvard.edu/~caram/PDFs/1976_Hersh_Caramazza_JEPG.pdf) (recommended by Staffan) 2017-10-13

  * J. Andreas, M. Rohrbach, T. Darrell, and D. Klein. Learning to compose neural networks for question answering. CoRR, abs/1601.01705:1–10, 2016. [link](https://arxiv.org/abs/1601.01705) (recommended by Mehdi), 2017-09-29
